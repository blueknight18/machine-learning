{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "STEPS = 12000\n",
    "BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(DATA_DIR, one_hot=True) #the class is represented as binary string of length 10 with a single 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size : 25 \tLearning Rate: 0.014712665786140493 \tAccuracy: 85.51\n",
      "Batch Size : 50 \tLearning Rate: 0.014712665786140493 \tAccuracy: 84.96\n",
      "Batch Size : 75 \tLearning Rate: 0.014712665786140493 \tAccuracy: 84.75\n",
      "Batch Size : 100 \tLearning Rate: 0.014712665786140493 \tAccuracy: 85.14\n",
      "Batch Size : 125 \tLearning Rate: 0.014712665786140493 \tAccuracy: 85.29\n",
      "Batch Size : 150 \tLearning Rate: 0.014712665786140493 \tAccuracy: 84.52\n",
      "Batch Size : 175 \tLearning Rate: 0.014712665786140493 \tAccuracy: 85.77\n",
      "Batch Size : 200 \tLearning Rate: 0.014712665786140493 \tAccuracy: 84.1\n",
      "\n",
      "\n",
      "Batch Size : 25 \tLearning Rate: 0.18727545204565488 \tAccuracy: 90.98\n",
      "Batch Size : 50 \tLearning Rate: 0.18727545204565488 \tAccuracy: 90.71\n",
      "Batch Size : 75 \tLearning Rate: 0.18727545204565488 \tAccuracy: 90.91\n",
      "Batch Size : 100 \tLearning Rate: 0.18727545204565488 \tAccuracy: 91.0\n",
      "Batch Size : 125 \tLearning Rate: 0.18727545204565488 \tAccuracy: 91.0\n",
      "Batch Size : 150 \tLearning Rate: 0.18727545204565488 \tAccuracy: 91.21\n",
      "Batch Size : 175 \tLearning Rate: 0.18727545204565488 \tAccuracy: 91.11\n",
      "Batch Size : 200 \tLearning Rate: 0.18727545204565488 \tAccuracy: 91.08\n",
      "\n",
      "\n",
      "Batch Size : 25 \tLearning Rate: 0.1737639243665515 \tAccuracy: 90.37\n",
      "Batch Size : 50 \tLearning Rate: 0.1737639243665515 \tAccuracy: 90.53\n",
      "Batch Size : 75 \tLearning Rate: 0.1737639243665515 \tAccuracy: 90.9\n",
      "Batch Size : 100 \tLearning Rate: 0.1737639243665515 \tAccuracy: 90.92\n",
      "Batch Size : 125 \tLearning Rate: 0.1737639243665515 \tAccuracy: 91.05\n",
      "Batch Size : 150 \tLearning Rate: 0.1737639243665515 \tAccuracy: 90.61\n",
      "Batch Size : 175 \tLearning Rate: 0.1737639243665515 \tAccuracy: 91.1\n",
      "Batch Size : 200 \tLearning Rate: 0.1737639243665515 \tAccuracy: 90.96\n",
      "\n",
      "\n",
      "Batch Size : 25 \tLearning Rate: 0.7261873892149411 \tAccuracy: 90.69\n",
      "Batch Size : 50 \tLearning Rate: 0.7261873892149411 \tAccuracy: 91.67\n",
      "Batch Size : 75 \tLearning Rate: 0.7261873892149411 \tAccuracy: 91.54\n",
      "Batch Size : 100 \tLearning Rate: 0.7261873892149411 \tAccuracy: 91.96\n",
      "Batch Size : 125 \tLearning Rate: 0.7261873892149411 \tAccuracy: 92.14\n",
      "Batch Size : 150 \tLearning Rate: 0.7261873892149411 \tAccuracy: 92.22\n",
      "Batch Size : 175 \tLearning Rate: 0.7261873892149411 \tAccuracy: 91.82\n",
      "Batch Size : 200 \tLearning Rate: 0.7261873892149411 \tAccuracy: 91.96\n",
      "\n",
      "\n",
      "Batch Size : 25 \tLearning Rate: 0.7866012353708294 \tAccuracy: 90.87\n",
      "Batch Size : 50 \tLearning Rate: 0.7866012353708294 \tAccuracy: 90.99\n",
      "Batch Size : 75 \tLearning Rate: 0.7866012353708294 \tAccuracy: 91.1\n",
      "Batch Size : 100 \tLearning Rate: 0.7866012353708294 \tAccuracy: 92.11\n",
      "Batch Size : 125 \tLearning Rate: 0.7866012353708294 \tAccuracy: 91.7\n",
      "Batch Size : 150 \tLearning Rate: 0.7866012353708294 \tAccuracy: 92.23\n",
      "Batch Size : 175 \tLearning Rate: 0.7866012353708294 \tAccuracy: 91.85\n",
      "Batch Size : 200 \tLearning Rate: 0.7866012353708294 \tAccuracy: 92.27\n",
      "\n",
      "\n",
      "Batch Size : 25 \tLearning Rate: 0.13912119780769222 \tAccuracy: 90.26\n",
      "Batch Size : 50 \tLearning Rate: 0.13912119780769222 \tAccuracy: 90.31\n",
      "Batch Size : 75 \tLearning Rate: 0.13912119780769222 \tAccuracy: 90.46\n",
      "Batch Size : 100 \tLearning Rate: 0.13912119780769222 \tAccuracy: 90.71\n",
      "Batch Size : 125 \tLearning Rate: 0.13912119780769222 \tAccuracy: 90.72\n",
      "Batch Size : 150 \tLearning Rate: 0.13912119780769222 \tAccuracy: 90.5\n",
      "Batch Size : 175 \tLearning Rate: 0.13912119780769222 \tAccuracy: 90.7\n",
      "Batch Size : 200 \tLearning Rate: 0.13912119780769222 \tAccuracy: 90.22\n",
      "\n",
      "\n",
      "Batch Size : 25 \tLearning Rate: 0.8263821408893942 \tAccuracy: 91.52\n",
      "Batch Size : 50 \tLearning Rate: 0.8263821408893942 \tAccuracy: 90.6\n",
      "Batch Size : 75 \tLearning Rate: 0.8263821408893942 \tAccuracy: 91.08\n",
      "Batch Size : 100 \tLearning Rate: 0.8263821408893942 \tAccuracy: 91.76\n",
      "Batch Size : 125 \tLearning Rate: 0.8263821408893942 \tAccuracy: 91.77\n",
      "Batch Size : 150 \tLearning Rate: 0.8263821408893942 \tAccuracy: 91.92\n",
      "Batch Size : 175 \tLearning Rate: 0.8263821408893942 \tAccuracy: 92.25\n",
      "Batch Size : 200 \tLearning Rate: 0.8263821408893942 \tAccuracy: 92.09\n",
      "\n",
      "\n",
      "Batch Size : 25 \tLearning Rate: 0.07842376265465845 \tAccuracy: 89.89\n",
      "Batch Size : 50 \tLearning Rate: 0.07842376265465845 \tAccuracy: 89.58\n",
      "Batch Size : 75 \tLearning Rate: 0.07842376265465845 \tAccuracy: 89.44\n",
      "Batch Size : 100 \tLearning Rate: 0.07842376265465845 \tAccuracy: 89.95\n",
      "Batch Size : 125 \tLearning Rate: 0.07842376265465845 \tAccuracy: 89.93\n",
      "Batch Size : 150 \tLearning Rate: 0.07842376265465845 \tAccuracy: 89.82\n",
      "Batch Size : 175 \tLearning Rate: 0.07842376265465845 \tAccuracy: 89.8\n",
      "Batch Size : 200 \tLearning Rate: 0.07842376265465845 \tAccuracy: 89.79\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(8):\n",
    "    learning_rate = np.random.uniform(0.01,1,None)\n",
    "    for j in range(25,201,25):\n",
    "        BATCH_SIZE = j\n",
    "        X = tf.placeholder(tf.float32, [None, 784])\n",
    "        W = tf.Variable(tf.truncated_normal([784,10]))\n",
    "        b = tf.Variable(tf.zeros([1,10]))\n",
    "        y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "        y_pred = tf.matmul(X,W)+b\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "        optim = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "        correct = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(STEPS):\n",
    "                x, y = data.train.next_batch(BATCH_SIZE)\n",
    "                sess.run(optim, feed_dict={X: x, y_true: y})\n",
    "                if i == STEPS - 1:\n",
    "                    acc = sess.run(accuracy, feed_dict={X: data.test.images, y_true: data.test.labels})\n",
    "                    print(\"Batch Size : {}\".format(j), \"\\tLearning Rate: {}\".format(learning_rate), \"\\tAccuracy: {:.4}\".format(acc*100))\n",
    "    print(\"\\n\")            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
